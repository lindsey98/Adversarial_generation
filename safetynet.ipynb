{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import torchvision.models as models\n",
    "import os\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)\n",
    "from shutil import copyfile\n",
    "for i in range(10000, 20000):\n",
    "    copyfile('jsma_perturbed_images/0.1/' + str(i) + '.png', 'safetynet-jsma-test/photos/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)\n",
    "# CIFAR10 Test dataset and dataloader declaration\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='safetynet-normal-train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10000,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "adversarialset = torchvision.datasets.ImageFolder(root='safetynet-jsma-train', transform=transform)\n",
    "adversarialloader = torch.utils.data.DataLoader(adversarialset, batch_size=10000,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "totaltrainloader = torch.utils.data.DataLoader(\n",
    "             torch.utils.data.ConcatDataset([\n",
    "                 trainset,\n",
    "                 adversarialset]),\n",
    "             batch_size=20000, shuffle=False,\n",
    "             num_workers=5)\n",
    "\n",
    "print(2)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='safetynet-normal-test', transform=transform)\n",
    "testadversarialset = torchvision.datasets.ImageFolder(root='safetynet-jsma-test', transform=transform)\n",
    "totaltestloader = torch.utils.data.DataLoader(\n",
    "             torch.utils.data.ConcatDataset([\n",
    "                 testset,\n",
    "                 testadversarialset]),\n",
    "             batch_size=20000, shuffle=False,\n",
    "             num_workers=5)\n",
    "\n",
    "print(3)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the network\n",
    "model = models.vgg16(pretrained=True)\n",
    "model.fc = nn.Linear(2048, 10)\n",
    "\n",
    "# freeze front layers\n",
    "ct = 0\n",
    "for child in model.children():\n",
    "    ct += 1\n",
    "    if ct < 5:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "model = model.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.1, step_size=30)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    \"\"\"\n",
    "        Run one train epoch\n",
    "    \"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.to(device)\n",
    "        input = input.to(device)\n",
    "        target_var = target\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # measure accuracy and record loss\n",
    "        _, predicted = output.max(1)\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Accuracy {acc:.3f}'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses, acc=correct/total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state,filename='checkpoint.pth.tar'):\n",
    "    \"\"\"\n",
    "    Save the training model\n",
    "    \"\"\"\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global best_prec1\n",
    "best_prec1 = 0\n",
    "\n",
    "for epoch in range(50):\n",
    "\n",
    "    # train for one epoch\n",
    "    print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if epoch > 0 and epoch % 50 == 0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict()\n",
    "        },  filename=os.path.join('./checkpoints/', 'checkpoint2.th'))\n",
    "\n",
    "    save_checkpoint({\n",
    "        'state_dict': model.state_dict()\n",
    "    },  filename=os.path.join('./checkpoints/', 'model2.th'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the safetynet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"START\")\n",
    "model.load_state_dict(torch.load('./checkpoints/model2.th')['state_dict'])\n",
    "model.eval()\n",
    "model2 = nn.Sequential(*list(model.children())[:-2])\n",
    "#print(model2)\n",
    "inputs, labels = next(iter(totaltrainloader))\n",
    "inputs, labels = Variable(inputs), Variable(labels)\n",
    "#outputs = model2(inputs)\n",
    "#print(inputs)\n",
    "#print(outputs)\n",
    "print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny, nz = inputs.shape\n",
    "print(nsamples, nx, ny, nz)\n",
    "inputs = inputs.reshape(nsamples,nx*ny*nz)\n",
    "\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "totaltrainsetlabels = []\n",
    "for i in range(10000):\n",
    "    totaltrainsetlabels.append(1)\n",
    "    \n",
    "for i in range(10000):\n",
    "    totaltrainsetlabels.append(-1)\n",
    "    \n",
    "totaltrainsetlabels = np.array(totaltrainsetlabels)\n",
    "\n",
    "C_2d_range = [1e-2, 1, 1e2]\n",
    "gamma_2d_range = [1e-1, 1, 1e1]\n",
    "classifiers = []\n",
    "for C in C_2d_range:\n",
    "    for gamma in gamma_2d_range:\n",
    "        print(C, gamma)\n",
    "        clf = SVC(C=C, gamma=gamma)\n",
    "        clf.fit(inputs.detach().numpy(), totaltrainsetlabels)\n",
    "        \n",
    "        classifiers.append((C, gamma, clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(totaltestloader)\n",
    "\n",
    "inputs2, labels2 = next(it)\n",
    "inputs2, labels2 = Variable(inputs2), Variable(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny, nz = inputs2.shape\n",
    "print(nsamples, nx, ny, nz)\n",
    "inputs2 = inputs2.reshape(nsamples,nx*ny*nz)\n",
    "\n",
    "print(inputs)\n",
    "print(inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for classifier in classifiers:\n",
    "    results.append(classifier[2].predict(inputs2.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    for i in range(10000):\n",
    "        if result[i] == 1:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "    for i in range(10000, 20000):\n",
    "        if result[i] == -1:\n",
    "            TN += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "    print(TP)\n",
    "    print(FP)\n",
    "    print(TN)\n",
    "    print(FN)\n",
    "    print()\n",
    "    print()\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "temploader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "temp2 = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "temp2loader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "temptotalloader = torch.utils.data.DataLoader(\n",
    "             torch.utils.data.ConcatDataset([\n",
    "                 temp,\n",
    "                 temp2]),\n",
    "             batch_size=2, shuffle=False,\n",
    "             num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_temp = iter(temptotalloader)\n",
    "next_temp, labels_temp = next(it_temp)\n",
    "next_temp, labels_temp = Variable(next_temp), Variable(labels_temp)\n",
    "print(next_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next_temp.shape)\n",
    "for imageArr in next_temp:\n",
    "    im = Image.fromarray((imageArr.detach().numpy() * 255).astype(np.uint8))\n",
    "    im.save(\"temp/\" + \"temp.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_attack(image, epsilon, data_grad, attack_method):\n",
    "    assert attack_method in ['fgsm', 'stepll', 'jsma'] \n",
    "    \n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = torch.sign(data_grad)\n",
    "    \n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    if attack_method == 'fgsm':\n",
    "        perturbed_image = image + epsilon*sign_data_grad\n",
    "    else:\n",
    "        perturbed_image = image - epsilon*sign_data_grad\n",
    "        \n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion, attack_method, epsilon):\n",
    "    assert attack_method in ['fgsm', 'stepll', 'jsma'] \n",
    "    \n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        print(output)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "        if init_pred.item() != target.item(): # initially was incorrect --> no need to generate adversary\n",
    "            continue\n",
    "        \n",
    "        if attack_method == 'fgsm':\n",
    "            loss = criterion(output, target) # loss for ground-truth class\n",
    "        else:\n",
    "            ll = output.min(1, keepdim=True)[1][0]\n",
    "            loss = criterion(output, ll)  # Loss for least-likely class\n",
    "            \n",
    "        # Back propogation\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect data_grad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call Attack\n",
    "        perturbed_data = adv_attack(data, epsilon, data_grad, attack_method)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1 # still correct\n",
    "            # Special case for saving 0 epsilon examples\n",
    "        adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "        adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))\n",
    "        total += 1\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, total, final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "attack_method = 'fgsm'\n",
    "\n",
    "for eps in epsilons:\n",
    "    print(eps)\n",
    "    acc, ex = test(model, device, testloader, criterion, attack_method, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons[:len(accuracies)], accuracies, \"*-\")\n",
    "# plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "# plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "attack_method = 'stepll'\n",
    "\n",
    "for eps in epsilons:\n",
    "    acc, ex = test(model, device, testloader, criterion, attack_method, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons[:len(accuracies)], accuracies, \"*-\")\n",
    "# plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "# plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_cifar10_data(filename):\n",
    "    with open('data/cifar-10-batches-py/'+ filename, 'rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    features = batch['data']\n",
    "    labels = batch['labels']\n",
    "    return features, labels\n",
    "\n",
    "batch_1, labels_1 = load_cifar10_data('test_batch')\n",
    "print(labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
