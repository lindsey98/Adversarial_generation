{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use Deepfool method to craft adversarial on CIFAR10.\n",
    "\n",
    "Note that instead of find the optimized image for each image, we do a batched\n",
    "attack without binary search for the best possible solution.  Thus, the result\n",
    "is worse than reported in the original paper.  To achieve the best result\n",
    "requires more computation, as demonstrated in another example.\n",
    "\"\"\"\n",
    "import os\n",
    "from timeit import default_timer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')           # noqa: E402\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from attacks import deepfool\n",
    "\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "img_size = 32\n",
    "img_chan = 3\n",
    "n_classes = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer(object):\n",
    "    def __init__(self, msg='Starting.....', timer=default_timer, factor=1,\n",
    "                 fmt=\"------- elapsed {:.4f}s --------\"):\n",
    "        self.timer = timer\n",
    "        self.factor = factor\n",
    "        self.fmt = fmt\n",
    "        self.end = None\n",
    "        self.msg = msg\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        Return the current time\n",
    "        \"\"\"\n",
    "        return self.timer()\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"\n",
    "        Set the start time\n",
    "        \"\"\"\n",
    "        print(self.msg)\n",
    "        self.start = self()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_traceback):\n",
    "        \"\"\"\n",
    "        Set the end time\n",
    "        \"\"\"\n",
    "        self.end = self()\n",
    "        print(str(self))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.fmt.format(self.elapsed)\n",
    "\n",
    "    @property\n",
    "    def elapsed(self):\n",
    "        if self.end is None:\n",
    "            # if elapsed is called in the context manager scope\n",
    "            return (self() - self.start) * self.factor\n",
    "        else:\n",
    "            # if elapsed is called out of the context manager scope\n",
    "            return (self.end - self.start) * self.factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading CIFAR10\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading CIFAR10')\n",
    "\n",
    "cifar = tf.keras.datasets.cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar.load_data()\n",
    "print(np.shape(X_train))\n",
    "X_train = np.reshape(X_train, [-1, img_size, img_size, img_chan])\n",
    "X_train = X_train.astype(np.float32) / 255\n",
    "X_test = np.reshape(X_test, [-1, img_size, img_size, img_chan])\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "\n",
    "to_categorical = tf.keras.utils.to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spliting data\n"
     ]
    }
   ],
   "source": [
    "print('\\nSpliting data')\n",
    "\n",
    "ind = np.random.permutation(X_train.shape[0])\n",
    "X_train, y_train = X_train[ind], y_train[ind]\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "n = int(X_train.shape[0] * (1-VALIDATION_SPLIT))\n",
    "X_valid = X_train[n:]\n",
    "X_train = X_train[:n]\n",
    "y_valid = y_train[n:]\n",
    "y_train = y_train[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construction graph\n",
      "WARNING:tensorflow:From <ipython-input-6-f5e0317132dc>:5: conv2d (from tensorflow.python.keras.legacy_tf_layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-f5e0317132dc>:7: max_pooling2d (from tensorflow.python.keras.legacy_tf_layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-f5e0317132dc>:19: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-f5e0317132dc>:20: dropout (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /Users/i537199/Desktop/Adversarial_generation/attacks/deepfool.py:48: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "print('\\nConstruction graph')\n",
    "\n",
    "def model(x, logits=False, training=False):\n",
    "    with tf.variable_scope('conv0'):\n",
    "        z = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3],\n",
    "                             padding='same', activation=tf.nn.relu)\n",
    "        z = tf.layers.max_pooling2d(z, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    with tf.variable_scope('conv1'):\n",
    "        z = tf.layers.conv2d(z, filters=64, kernel_size=[3, 3],\n",
    "                             padding='same', activation=tf.nn.relu)\n",
    "        z = tf.layers.max_pooling2d(z, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    with tf.variable_scope('flatten'):\n",
    "        shape = z.get_shape().as_list()\n",
    "        z = tf.reshape(z, [-1, np.prod(shape[1:])])\n",
    "\n",
    "    with tf.variable_scope('mlp'):\n",
    "        z = tf.layers.dense(z, units=128, activation=tf.nn.relu)\n",
    "        z = tf.layers.dropout(z, rate=0.25, training=training)\n",
    "\n",
    "    logits_ = tf.layers.dense(z, units=10, name='logits')\n",
    "    y = tf.nn.softmax(logits_, name='ybar')\n",
    "\n",
    "    if logits:\n",
    "        return y, logits_\n",
    "    return y\n",
    "\n",
    "\n",
    "class Dummy:\n",
    "    pass\n",
    "\n",
    "\n",
    "env = Dummy()\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "with tf.variable_scope('model', reuse = tf.AUTO_REUSE):\n",
    "    env.x = tf.placeholder(tf.float32, (None, img_size, img_size, img_chan),\n",
    "                           name='x')\n",
    "    env.y = tf.placeholder(tf.float32, (None, n_classes), name='y')\n",
    "    env.training = tf.placeholder_with_default(False, (), name='mode')\n",
    "\n",
    "    env.ybar, logits = model(env.x, logits=True, training=env.training)\n",
    "\n",
    "    with tf.variable_scope('acc'):\n",
    "        count = tf.equal(tf.argmax(env.y, axis=1), tf.argmax(env.ybar, axis=1))\n",
    "        env.acc = tf.reduce_mean(tf.cast(count, tf.float32), name='acc')\n",
    "\n",
    "    with tf.variable_scope('loss'):\n",
    "        xent = tf.nn.softmax_cross_entropy_with_logits(labels=env.y,\n",
    "                                                       logits=logits)\n",
    "        env.loss = tf.reduce_mean(xent, name='loss')\n",
    "\n",
    "    with tf.variable_scope('train_op'):\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        env.train_op = optimizer.minimize(env.loss)\n",
    "\n",
    "    env.saver = tf.train.Saver()\n",
    "\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    env.adv_epochs = tf.placeholder(tf.int32, (), name='adv_epochs')\n",
    "    env.xadv = deepfool(model, env.x, epochs=env.adv_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing graph\n"
     ]
    }
   ],
   "source": [
    "print('\\nInitializing graph')\n",
    "\n",
    "env.sess = tf.InteractiveSession()\n",
    "env.sess.run(tf.global_variables_initializer())\n",
    "env.sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(env, X_data, y_data, batch_size=128):\n",
    "    \"\"\"\n",
    "    Evaluate TF model by running env.loss and env.acc.\n",
    "    \"\"\"\n",
    "    print('\\nEvaluating')\n",
    "\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
    "    loss, acc = 0, 0\n",
    "\n",
    "    for batch in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "        start = batch * batch_size\n",
    "        end = min(n_sample, start + batch_size)\n",
    "        cnt = end - start\n",
    "        batch_loss, batch_acc = env.sess.run(\n",
    "            [env.loss, env.acc],\n",
    "            feed_dict={env.x: X_data[start:end],\n",
    "                       env.y: y_data[start:end]})\n",
    "        loss += batch_loss * cnt\n",
    "        acc += batch_acc * cnt\n",
    "    loss /= n_sample\n",
    "    acc /= n_sample\n",
    "\n",
    "    print(' loss: {0:.4f} acc: {1:.4f}'.format(loss, acc))\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def train(env, X_data, y_data, X_valid=None, y_valid=None, epochs=1,\n",
    "          load=False, shuffle=True, batch_size=128, name='model'):\n",
    "    \"\"\"\n",
    "    Train a TF model by running env.train_op.\n",
    "    \"\"\"\n",
    "    if load:\n",
    "        if not hasattr(env, 'saver'):\n",
    "            return print('\\nError: cannot find saver op')\n",
    "        print('\\nLoading saved model')\n",
    "        return env.saver.restore(env.sess, 'model/{}'.format(name))\n",
    "\n",
    "    print('\\nTrain model')\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        print('\\nEpoch {0}/{1}'.format(epoch + 1, epochs))\n",
    "\n",
    "        if shuffle:\n",
    "            print('\\nShuffling data')\n",
    "            ind = np.arange(n_sample)\n",
    "            np.random.shuffle(ind)\n",
    "            X_data = X_data[ind]\n",
    "            y_data = y_data[ind]\n",
    "\n",
    "        for batch in range(n_batch):\n",
    "            print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "            start = batch * batch_size\n",
    "            end = min(n_sample, start + batch_size)\n",
    "            env.sess.run(env.train_op, feed_dict={env.x: X_data[start:end],\n",
    "                                                  env.y: y_data[start:end],\n",
    "                                                  env.training: True})\n",
    "        if X_valid is not None:\n",
    "            evaluate(env, X_valid, y_valid)\n",
    "\n",
    "    if hasattr(env, 'saver'):\n",
    "        print('\\n Saving model')\n",
    "        os.makedirs('model', exist_ok=True)\n",
    "        env.saver.save(env.sess, 'model/{}'.format(name))\n",
    "\n",
    "\n",
    "def predict(env, X_data, batch_size=128):\n",
    "    \"\"\"\n",
    "    Do inference by running env.ybar.\n",
    "    \"\"\"\n",
    "    print('\\nPredicting')\n",
    "    n_classes = env.ybar.get_shape().as_list()[1]\n",
    "\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
    "    yval = np.empty((n_sample, n_classes))\n",
    "\n",
    "    for batch in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "        start = batch * batch_size\n",
    "        end = min(n_sample, start + batch_size)\n",
    "        y_batch = env.sess.run(env.ybar, feed_dict={env.x: X_data[start:end]})\n",
    "        yval[start:end] = y_batch\n",
    "    print()\n",
    "    return yval\n",
    "\n",
    "\n",
    "# To do the boundary analysis for adversarial samples\n",
    "def boundary_analysis(sess, env, X_data, y_data, batch_size=128):\n",
    "    \"\"\"\n",
    "    Evaluate TF model by running env.loss and env.acc.\n",
    "    \"\"\"\n",
    "    n_classes = env.ybar.get_shape().as_list()[1]\n",
    "\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
    "    yval = np.empty((n_sample, n_classes))\n",
    "\n",
    "    img_count = 0\n",
    "    diff_confidence_score_total = 0.0\n",
    "    for batch in range(n_batch):\n",
    "        #print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "        start = batch * batch_size\n",
    "        end = min(n_sample, start + batch_size)\n",
    "        y_batch = env.sess.run(env.ybar, feed_dict={env.x: X_data[start:end]})\n",
    "        for yy in y_batch:\n",
    "            yy2 = yy.tolist()\n",
    "            yy2.sort(reverse=True)\n",
    "            first_confidence_score = yy2[0]\n",
    "            second_confidence_score = yy2[1]\n",
    "            diff_confidence_score = first_confidence_score - second_confidence_score\n",
    "            diff_confidence_score_total += diff_confidence_score\n",
    "            img_count += 1\n",
    "        yval[start:end] = y_batch\n",
    "    print(diff_confidence_score_total / img_count)\n",
    "    print()\n",
    "    return yval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_deepfool(sess, env, X_data, epochs=1, eps=0.01, batch_size=128):\n",
    "    \"\"\"\n",
    "    Generate DeepFool by running env.xadv.\n",
    "    \"\"\"\n",
    "    print('\\nMaking adversarials via DeepFool')\n",
    "\n",
    "    startTime = time.time()\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample + batch_size - 1) / batch_size)\n",
    "    X_adv = np.empty_like(X_data)\n",
    "\n",
    "    for batch in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "        start = batch * batch_size\n",
    "        end = min(n_sample, start + batch_size)\n",
    "        adv = sess.run(env.xadv, feed_dict={env.x: X_data[start:end],\n",
    "                                            env.adv_epochs: epochs})\n",
    "        X_adv[start:end] = adv\n",
    "    print()\n",
    "    endTime = time.time()\n",
    "    print(endTime - startTime)\n",
    "\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTraining')\n",
    "\n",
    "train(env, X_train, y_train, X_valid, y_valid, load=False, epochs=5,\n",
    "      name='cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on clean data\n",
      "\n",
      "Evaluating\n",
      " loss: 2.3223 acc: 0.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.3222914916992186, 0.0999)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nEvaluating on clean data')\n",
    "\n",
    "evaluate(env, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating adversarial data\n",
      "WARNING:tensorflow:From /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/i537199/Desktop/Adversarial_generation/attacks/deepfool.py:44 _f  *\n        z = fn(model, xi, eta=eta, epochs=epochs, clip_min=clip_min,\n    /Users/i537199/Desktop/Adversarial_generation/attacks/deepfool.py:120 deepfoolx  *\n        y0 = tf.stop_gradient(model(x))\n    <ipython-input-6-f5e0317132dc>:5 model  *\n        z = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3],\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:324 new_func  **\n        return func(*args, **kwargs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:424 conv2d\n        return layer.apply(inputs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:324 new_func\n        return func(*args, **kwargs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:2226 apply\n        return self.__call__(inputs, *args, **kwargs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py:547 __call__\n        outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:982 __call__\n        self._maybe_build(inputs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py:197 build\n        self.kernel = self.add_weight(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py:448 add_weight\n        variable = super(Layer, self).add_weight(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:597 add_weight\n        variable = self._add_variable_with_custom_getter(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:745 _add_variable_with_custom_getter\n        new_variable = getter(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:1556 get_variable\n        return get_variable_scope().get_variable(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:1299 get_variable\n        return var_store.get_variable(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:554 get_variable\n        return _true_getter(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:507 _true_getter\n        return self._get_single_variable(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:863 _get_single_variable\n        raise ValueError(err_msg)\n\n    ValueError: Variable conv0/conv2d/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-57010981cc5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nGenerating adversarial data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepfool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#X_adv1 = deepfool(model, X_test, noise=False, eta=0.01, epochs=3, clip_min=0.0, clip_max=1.0, min_prob=0.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#X_adv2 = deepfool(model, X_test, noise=False, eta=0.01, epochs=3, clip_min=0.0, clip_max=1.0, min_prob=0.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Adversarial_generation/attacks/deepfool.py\u001b[0m in \u001b[0;36mdeepfool\u001b[0;34m(model, x, noise, eta, epochs, batch, clip_min, clip_max, min_prob)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         delta = tf.map_fn(_f, x, dtype=(tf.float32), back_prop=False,\n\u001b[0m\u001b[1;32m     49\u001b[0m                           name='deepfool')\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/map_fn.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    491\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     _, r_a = control_flow_ops.while_loop(\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mcompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_batchable_ta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2685\u001b[0m   if (util.EnableControlFlowV2(ops.get_default_graph()) and\n\u001b[1;32m   2686\u001b[0m       not executing_eagerly):\n\u001b[0;32m-> 2687\u001b[0;31m     return while_v2.while_loop(\n\u001b[0m\u001b[1;32m   2688\u001b[0m         \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloop_counter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_iterations_arg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     body_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mbody_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mwrapped_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwrapped_body\u001b[0;34m(loop_counter, maximum_iterations_arg, *args)\u001b[0m\n\u001b[1;32m    172\u001b[0m       \u001b[0;31m# `orig_loop_vars` and `args`, converts flows in `args` to TensorArrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m       \u001b[0;31m# and packs it into the structure of `orig_loop_vars`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/map_fn.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(i, tas)\u001b[0m\n\u001b[1;32m    481\u001b[0m       \u001b[0mag_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m       \u001b[0mautographed_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m       \u001b[0mresult_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautographed_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m       \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_output_signature\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0mresult_value_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/i537199/Desktop/Adversarial_generation/attacks/deepfool.py:44 _f  *\n        z = fn(model, xi, eta=eta, epochs=epochs, clip_min=clip_min,\n    /Users/i537199/Desktop/Adversarial_generation/attacks/deepfool.py:120 deepfoolx  *\n        y0 = tf.stop_gradient(model(x))\n    <ipython-input-6-f5e0317132dc>:5 model  *\n        z = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3],\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:324 new_func  **\n        return func(*args, **kwargs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:424 conv2d\n        return layer.apply(inputs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:324 new_func\n        return func(*args, **kwargs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:2226 apply\n        return self.__call__(inputs, *args, **kwargs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py:547 __call__\n        outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:982 __call__\n        self._maybe_build(inputs)\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py:197 build\n        self.kernel = self.add_weight(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py:448 add_weight\n        variable = super(Layer, self).add_weight(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:597 add_weight\n        variable = self._add_variable_with_custom_getter(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:745 _add_variable_with_custom_getter\n        new_variable = getter(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:1556 get_variable\n        return get_variable_scope().get_variable(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:1299 get_variable\n        return var_store.get_variable(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:554 get_variable\n        return _true_getter(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:507 _true_getter\n        return self._get_single_variable(\n    /Users/i537199/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py:863 _get_single_variable\n        raise ValueError(err_msg)\n\n    ValueError: Variable conv0/conv2d/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?\n"
     ]
    }
   ],
   "source": [
    "print('\\nGenerating adversarial data')\n",
    "\n",
    "X_adv = deepfool(model, X_test, noise=False, eta=0.01, epochs=3, clip_min=0.0, clip_max=1.0, min_prob=0.0)\n",
    "#X_adv1 = deepfool(model, X_test, noise=False, eta=0.01, epochs=3, clip_min=0.0, clip_max=1.0, min_prob=0.0)\n",
    "#X_adv2 = deepfool(model, X_test, noise=False, eta=0.01, epochs=3, clip_min=0.0, clip_max=1.0, min_prob=0.0)\n",
    "#X_adv3 = deepfool(model, X_test, noise=False, eta=0.01, epochs=3, clip_min=0.0, clip_max=1.0, min_prob=0.0)\n",
    "#X_adv4 = deepfool(model, X_test, noise=False, eta=0.01, epochs=3, clip_min=0.0, clip_max=1.0, min_prob=0.0)\n",
    "#X_adv5 = deepfool(model, X_test, noise=False, eta=0.01, epochs=3, clip_min=0.0, clip_max=1.0, min_prob=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
